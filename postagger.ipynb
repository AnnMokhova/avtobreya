{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POS-тэггинг с CRFSuite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CRFSuite — одна из нескольких систем для последовательного теггинга, основанных на CRF. В питоне есть обертка, `pycrfsuite`, которую мы и будем использовать.\n",
    "\n",
    "В качестве тренировочного и тестового корпуса мы возьмем фрагмент НКРЯ в 1 млн словоупотреблений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/max/Dropbox/Courses/HSE/CompLing/POS\n"
     ]
    }
   ],
   "source": [
    "# Этот модуль нужно установить командой pip install python-crfsuite в консоли\n",
    "import pycrfsuite\n",
    "import codecs\n",
    "\n",
    "# Это нужно заменить на папку с корпусом\n",
    "%cd '~/Dropbox/Courses/HSE/CompLing/POS/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Загрузка корпуса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_ruscorpora(filename):\n",
    "    sent = [[]]\n",
    "    with codecs.open(filename) as inp_file:\n",
    "        for line in inp_file:\n",
    "            line = line.strip('\\r\\n ')\n",
    "            if '\\t' in line:\n",
    "                line = line[:line.find('\\t')]\n",
    "            if line.startswith('#'):\n",
    "                continue\n",
    "            if not line:\n",
    "                sent.append([])\n",
    "                continue\n",
    "            wordform, lemma, gram = line.rsplit('/', 2)\n",
    "            pos = gram[:gram.find('=')] if '=' in gram else gram\n",
    "            pos = pos.split(',')[0]\n",
    "            sent[-1].append((wordform, pos, lemma, gram))\n",
    "    \n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus = read_ruscorpora('ruscorpora.parsed.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Якутское A якутский A=n,sg,nom,plen\n",
      "отделение S отделение S,n,inan=sg,nom\n",
      "Единой A единый A=f,sg,gen,plen\n",
      "России S Россия S,f,inan=sg,gen\n",
      "планирует V планировать V,ipf,tran=sg,act,praes,3p,indic\n",
      "создать V создать V,pf,tran=inf,act\n",
      "комитеты S комитет S,m,inan=pl,acc\n",
      "партийного A партийный A=m,sg,gen,plen\n",
      "контроля S контроль S,m,inan=sg,gen\n",
      "наподобие PR наподобие PR\n",
      "существовавших V существовать V,ipf,intr,act=partcp,pl,gen,praet,plen\n",
      "в PR в PR\n",
      "СССР S СССР S,m,inan,0=sg,loc\n",
      "на PR на PR\n",
      "базе S база S,f,inan=sg,loc\n",
      "КПСС S КПСС S,f,inan,0=sg,gen\n"
     ]
    }
   ],
   "source": [
    "for word in corpus[0]:\n",
    "    print word[0], word[1], word[2], word[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Преобразование текста в фичи\n",
    "\n",
    "Для каждого токена в качестве признаков мы будем использовать само слово и его контекст — несколько слов слева и справа. Количество контекста передается в аргументе `n_context`.\n",
    "\n",
    "Если достаточного количества слов слева нет, то добавляется специальный признак начала предложения: `BOS`. Если нет контекста справа, то признак конца предложения: `EOS`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word2features(sent, i, n_context):\n",
    "    word = sent[i][0]\n",
    "\n",
    "    features = [\n",
    "        'word=' + word\n",
    "    ]\n",
    "    \n",
    "    for i_context in range(i-n_context, i):\n",
    "        if i_context >= 0:\n",
    "            features.extend([\n",
    "                    '-{}:word='.format(i_context) + sent[i_context][0]\n",
    "                ])\n",
    "        else:\n",
    "            features.append('BOS')\n",
    "    for i_context in range(i+1, i+1+n_context):\n",
    "        if i_context < len(sent):\n",
    "            features.extend([\n",
    "                    '+{}:word='.format(i_context) + sent[i_context][0]\n",
    "                ])\n",
    "        else:\n",
    "            features.append('EOS')\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вспомогательные функции для преобразования предложения в последовательность признаков и тегов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sent2features(sent, n_context):\n",
    "    return [word2features(sent, i, n_context) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [postag for token, postag, lemma, gram in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, lemma, gram in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['word=\\xd0\\xaf\\xd0\\xba\\xd1\\x83\\xd1\\x82\\xd1\\x81\\xd0\\xba\\xd0\\xbe\\xd0\\xb5',\n",
       " 'BOS',\n",
       " 'BOS',\n",
       " '+1:word=\\xd0\\xbe\\xd1\\x82\\xd0\\xb4\\xd0\\xb5\\xd0\\xbb\\xd0\\xb5\\xd0\\xbd\\xd0\\xb8\\xd0\\xb5',\n",
       " '+2:word=\\xd0\\x95\\xd0\\xb4\\xd0\\xb8\\xd0\\xbd\\xd0\\xbe\\xd0\\xb9']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent2features(corpus[0], 2)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90703"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разобьем корпус на тестовую и тренировочную выборку случайным образом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.71 s, sys: 255 ms, total: 4.97 s\n",
      "Wall time: 9.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn import cross_validation\n",
    "\n",
    "n_context = 2\n",
    "\n",
    "X = [sent2features(s, n_context) for s in corpus]\n",
    "y = [sent2labels(s) for s in corpus]\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "#X_train = [sent2features(s, n_context) for s in corpus[10000:]]\n",
    "#y_train = [sent2labels(s) for s in corpus[10000:]]\n",
    "\n",
    "#X_test = [sent2features(s, n_context) for s in corpus[:10000]]\n",
    "#y_test = [sent2labels(s) for s in corpus[:10000]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь можно тренировать CRF. Сначала создаем объект, потом добавляем ему тренировочный пары по одной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.66 s, sys: 101 ms, total: 5.76 s\n",
      "Wall time: 5.58 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainer = pycrfsuite.Trainer(verbose=False)\n",
    "\n",
    "for xseq, yseq in zip(X_train, y_train):\n",
    "    trainer.append(xseq, yseq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Обучение\n",
    "Зададим некоторые параметры обучения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainer.set_params({\n",
    "    'c1': 1.0,   # coefficient for L1 penalty\n",
    "    'c2': 1e-3,  # coefficient for L2 penalty\n",
    "    'max_iterations': 50,  # stop earlier\n",
    "\n",
    "    # include transitions that are possible, but not observed\n",
    "    'feature.possible_transitions': True\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature.minfreq',\n",
       " 'feature.possible_states',\n",
       " 'feature.possible_transitions',\n",
       " 'c1',\n",
       " 'c2',\n",
       " 'max_iterations',\n",
       " 'num_memories',\n",
       " 'epsilon',\n",
       " 'period',\n",
       " 'delta',\n",
       " 'linesearch',\n",
       " 'max_linesearch']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустим обучение:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 30s, sys: 366 ms, total: 1min 30s\n",
      "Wall time: 1min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainer.train('ruscorpora.crfsuite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь у нас есть сохраненная модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 max disk 5.4M Jan  1 14:58 ./ruscorpora.crfsuite\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh ./ruscorpora.crfsuite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Загрузка натренированного тэггера и его тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.closing at 0x7fa47436a650>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('ruscorpora.crfsuite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Якутское отделение Единой России планирует создать комитеты партийного контроля наподобие существовавших в СССР на базе КПСС\n",
      "('Predicted:', 'A S A S V V S A S PR S PR S PR S S')\n",
      "('Correct:  ', 'A S A S V V S A S PR V PR S PR S S')\n"
     ]
    }
   ],
   "source": [
    "example_sent = corpus[0]\n",
    "print(' '.join(sent2tokens(example_sent)))\n",
    "\n",
    "print(\"Predicted:\", ' '.join(tagger.tag(sent2features(example_sent, n_context))))\n",
    "print(\"Correct:  \", ' '.join(sent2labels(example_sent)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/multiclass.py:194: DeprecationWarning: Direct support for sequence of sequences multilabel representation will be unavailable from version 0.17. Use sklearn.preprocessing.MultiLabelBinarizer to convert to a label indicator representation.\n",
      "  DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/multiclass.py:194: DeprecationWarning: Direct support for sequence of sequences multilabel representation will be unavailable from version 0.17. Use sklearn.preprocessing.MultiLabelBinarizer to convert to a label indicator representation.\n",
      "  DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/multiclass.py:194: DeprecationWarning: Direct support for sequence of sequences multilabel representation will be unavailable from version 0.17. Use sklearn.preprocessing.MultiLabelBinarizer to convert to a label indicator representation.\n",
      "  DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/multiclass.py:194: DeprecationWarning: Direct support for sequence of sequences multilabel representation will be unavailable from version 0.17. Use sklearn.preprocessing.MultiLabelBinarizer to convert to a label indicator representation.\n",
      "  DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/label.py:469: DeprecationWarning: The multilabel parameter is deprecated as of version 0.15 and will be removed in 0.17. The parameter is no longer necessary because the value is automatically inferred.\n",
      "  \"inferred.\", DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/multiclass.py:194: DeprecationWarning: Direct support for sequence of sequences multilabel representation will be unavailable from version 0.17. Use sklearn.preprocessing.MultiLabelBinarizer to convert to a label indicator representation.\n",
      "  DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/label.py:469: DeprecationWarning: The multilabel parameter is deprecated as of version 0.15 and will be removed in 0.17. The parameter is no longer necessary because the value is automatically inferred.\n",
      "  \"inferred.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.87      0.91      0.89     12261\n",
      "      A-PRO       0.96      0.96      0.96      8868\n",
      "        ADV       0.94      0.90      0.92      7958\n",
      "    ADV-PRO       0.95      0.91      0.93      5340\n",
      "       ANUM       0.92      0.73      0.81      1099\n",
      "       CONJ       0.96      0.98      0.97     12397\n",
      "       INIT       0.93      0.91      0.92       721\n",
      "       INTJ       0.92      0.66      0.77       261\n",
      "     NONLEX       0.94      0.62      0.75       887\n",
      "        NUM       0.97      0.95      0.96      5423\n",
      "    PARENTH       0.86      0.83      0.84      1332\n",
      "       PART       0.97      0.94      0.95      8710\n",
      "         PR       0.99      1.00      1.00     14316\n",
      "    PRAEDIC       0.84      0.80      0.82      2084\n",
      "PRAEDIC-PRO       0.86      0.86      0.86        21\n",
      "          S       0.97      0.99      0.98     21145\n",
      "      S-PRO       0.96      0.97      0.97     12373\n",
      "          V       0.97      0.95      0.96     19112\n",
      "\n",
      "avg / total       0.95      0.95      0.95    134308\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/multiclass.py:194: DeprecationWarning: Direct support for sequence of sequences multilabel representation will be unavailable from version 0.17. Use sklearn.preprocessing.MultiLabelBinarizer to convert to a label indicator representation.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "y_pred = [tagger.tag(xseq) for xseq in X_test]\n",
    "print classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Мы можем заметить, что самое плохое качество достигается на наименее важных категориях: `NONLEX`, `INTJ` и `PARENTH`. То есть на важных грамматических категориях качество на самом деле выше.\n",
    "\n",
    "Теперь попробуем разметить какое-нибудь предложение не из корпуса:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['S-PRO', 'A', 'S']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = u'Это тестовое предложение'\n",
    "tagger.tag(sent2features([[item] for item in sent.split(' ')], 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
